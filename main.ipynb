{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch-Implementation for EEG-ConvTransformer which proposed in citation[1]\n",
    "@Xin Zhang, SZU.\n",
    "\"\"\"\n",
    "### README\n",
    "Here presents a demo for training and test\n",
    "Before running, the visualized-image should be generated from EEG signals by run /preprocess/project2img.ipynb, read chapter 3.1 of citation for more details. Note that in this part there are some uncertain coding due to undisclosed details in citation [2]. It's welcome to help me to refine this repository.\n",
    "\n",
    "The proposed method (Called EEG-ConvTransformer) of citation[1] is implemented in /model. It should be no problem.\n",
    "\n",
    "### Ref\n",
    "`[1] Bagchi S, Bathula D R. EEG-ConvTransformer for single-trial EEG-based visual stimulus classification[J]. Pattern Recognition, 2022, 129: 108757.`\n",
    "\n",
    "`[2] Bashivan, et al. \"Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks.\" International conference on learning representations (2016).`\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from data_load.dataset import EEGImagesDataset\n",
    "from train_test import train_validate\n",
    "from model.conv_transformer import ConvTransformer\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data. The author[1] referenced Azimuthal Equidistant Projection[2] for EEG-Visualization. Their dataset have the same spacial shape:[w=32, h=32]. Since ref[2] shared their dataset and codes, so it's more lower-cost to use their dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "Images = sio.loadmat(\"sample_data/time_frames.mat\")[\"img\"]\n",
    "print(np.shape(Images))\n",
    "Label = (sio.loadmat(\"sample_data/labels.mat\")[\"lab\"]).astype(int)\n",
    "print(np.shape(Label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2670, 3, 32, 32)\n",
    "(2670, 7, 3, 32, 32)\n",
    "(2670,)\n",
    "(2670,)\n",
    "Choose among the patient : [ 1  2  3  4  6  7  8  9 10 11 12 14 15]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "choosen_patient = 9\n",
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images)\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "train_loader = DataLoader(Train, batch_size=batch_size)\n",
    "test_loader = DataLoader(Test, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the ConvTransformer[1] model and perform training and validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ConvTransformer(num_classes=16, channels=8, num_heads=2, E=16, F=256, T=32, depth=2)\n",
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = train_validate(model, train_loader, test_loader, n_epoch=60, learning_rate=0.00001, print_epoch=5, opti='Adam')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Begin Training for Patient 9\n",
    "[5, 100]\tloss: 1.375\tAccuracy : 0.296\t\tval-loss: 1.376\tval-Accuracy : 0.150\n",
    "[10, 100]\tloss: 1.362\tAccuracy : 0.302\t\tval-loss: 1.371\tval-Accuracy : 0.225\n",
    "[15, 100]\tloss: 1.352\tAccuracy : 0.302\t\tval-loss: 1.368\tval-Accuracy : 0.225\n",
    "[20, 100]\tloss: 1.342\tAccuracy : 0.302\t\tval-loss: 1.362\tval-Accuracy : 0.225\n",
    "[25, 100]\tloss: 1.312\tAccuracy : 0.302\t\tval-loss: 1.335\tval-Accuracy : 0.225\n",
    "[30, 100]\tloss: 1.191\tAccuracy : 0.302\t\tval-loss: 1.250\tval-Accuracy : 0.225\n",
    "[35, 100]\tloss: 0.981\tAccuracy : 0.586\t\tval-loss: 1.105\tval-Accuracy : 0.575\n",
    "[40, 100]\tloss: 0.836\tAccuracy : 0.605\t\tval-loss: 1.015\tval-Accuracy : 0.650\n",
    "[45, 100]\tloss: 0.760\tAccuracy : 0.611\t\tval-loss: 1.008\tval-Accuracy : 0.700\n",
    "[50, 100]\tloss: 0.677\tAccuracy : 0.654\t\tval-loss: 1.047\tval-Accuracy : 0.725\n",
    "[55, 100]\tloss: 0.561\tAccuracy : 0.753\t\tval-loss: 1.120\tval-Accuracy : 0.725\n",
    "[60, 100]\tloss: 0.421\tAccuracy : 0.833\t\tval-loss: 1.253\tval-Accuracy : 0.800\n",
    "[65, 100]\tloss: 0.301\tAccuracy : 0.895\t\tval-loss: 1.419\tval-Accuracy : 0.750\n",
    "[70, 100]\tloss: 0.212\tAccuracy : 0.944\t\tval-loss: 1.557\tval-Accuracy : 0.825\n",
    "[75, 100]\tloss: 0.145\tAccuracy : 0.969\t\tval-loss: 1.810\tval-Accuracy : 0.875\n",
    "[80, 100]\tloss: 0.096\tAccuracy : 0.981\t\tval-loss: 2.223\tval-Accuracy : 0.875\n",
    "[85, 100]\tloss: 0.063\tAccuracy : 0.994\t\tval-loss: 2.621\tval-Accuracy : 0.875\n",
    "[90, 100]\tloss: 0.043\tAccuracy : 0.994\t\tval-loss: 2.955\tval-Accuracy : 0.900\n",
    "[95, 100]\tloss: 0.031\tAccuracy : 0.994\t\tval-loss: 3.245\tval-Accuracy : 0.900\n",
    "[100, 100]\tloss: 0.023\tAccuracy : 0.994\t\tval-loss: 3.496\tval-Accuracy : 0.900\n",
    "Finished Training\n",
    " loss: 0.023\tAccuracy : 0.994\t\tval-loss: 3.496\tval-Accuracy : 0.900"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
